{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43d9215a-c993-4319-92c8-80188ffc1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daabb25-c4bb-4516-966e-1e4664ba267d",
   "metadata": {},
   "source": [
    "## First function :first stage scraping of the webpage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac11523-e5d8-4da2-8a9e-1ec58cb445ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create a dataframe of all the topics on the github links\n",
    "# Dataframe will contain the TOPIC_NAME , TOPIC_DESCRIPTION , TOPIC_LINK\n",
    "# first function name is \"first_stage_scraper()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6bb2b704-5c36-4a1e-a89e-3a79331f81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_stage_scraper():      # we do not need any parameters inside this function at this stage\n",
    "    URL_one = 'https://github.com/topics'\n",
    "    base_url = 'https://github.com'\n",
    "    response = requests.get(URL_one)        # we are downloading the content of the link at this stage\n",
    "    if response.status_code != 200:        # here we checked the status code \n",
    "        print(\"There might be something going wrong.\")\n",
    "    document = BeautifulSoup(response.text , 'html.parser')   # parsing the response.text not the response becoz it will be a \"response_object\"\n",
    "    topic_mention = document.find_all('p' , {'class':\"f3 lh-condensed mb-0 mt-1 Link--primary\"})\n",
    "    desc_mention = document.find_all('p' , {'class': 'f5 color-fg-muted mb-0 mt-1'})\n",
    "    link_mention = document.find_all('a' ,{'class':'no-underline flex-1 d-flex flex-column'})  # these three give all tags\n",
    "    \n",
    "    # create an list where all the topic or titles will be there\n",
    "    topic_mention_textlst = [topic_mention[i].text for i in range(len(topic_mention))]  # topic_mention is itself a list of topic_tags \n",
    "    # create a list where all the description will be there\n",
    "    desc_mention_textlst = [desc_mention[i].text.replace('\\n' , '').strip() for i in range(len(desc_mention))] # desc_mention is list of all desc_tags\n",
    "    # create a list of all the links of individual topics or titles \n",
    "    link_mention_textlst = [base_url+link_mention[i]['href'] for i in range(len(link_mention))]\n",
    "\n",
    "    return pd.DataFrame({'TOPIC_NAME' : topic_mention_textlst,\n",
    "                       'DESCRIPTION' : desc_mention_textlst ,\n",
    "                         'LINKS':link_mention_textlst})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70602b7a-d33d-4268-961f-bb886889aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPIC_NAME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>LINKS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D refers to the use of three-dimensional grap...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TOPIC_NAME                                        DESCRIPTION  \\\n",
       "0         3D  3D refers to the use of three-dimensional grap...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "\n",
       "                            LINKS  \n",
       "0    https://github.com/topics/3d  \n",
       "1  https://github.com/topics/ajax  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_stage_scraper().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002799f4-a126-486c-b633-1245c5ab92b9",
   "metadata": {},
   "source": [
    "## Second function : all_repositories_of _individual_topics_in_a_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f666b1a-a324-4ff7-8944-359420e0040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets inside each URL which is there in the first datarame created\n",
    "# It collects the username,repo_name,repo_links and star_counts\n",
    "# convert these datas into the dataframe \n",
    "# name of this function is 'all_repos_of_each_topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9438c036-df4e-4b73-b14e-fa6d1f55d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_repos_of_each_topic(page_url):  # it takes a parameter of individual links of each topic \n",
    "    response = requests.get(page_url)    # getting a response object from request library\n",
    "    document = BeautifulSoup(response.text , 'html.parser')\n",
    "    h3_class_mention = document.find_all('h3' , {'class':\"f3 color-fg-muted text-normal lh-condensed\"}) # this creates a list of all h3 class\n",
    "    star_tag_mention = document.find_all('span' , {'class':\"Counter js-social-count\"})   # this creates a list of all span class\n",
    "\n",
    "    all_repos_intopic_dict = {'USERNAME': [],\n",
    "                             'REPO_NAME' : [],\n",
    "                             'STARS' : [],\n",
    "                             'REPO_LINK':[]}\n",
    "    for i in range(len(h3_class_mention)):\n",
    "        repo_data = individual_repo_info(h3_class_mention[i] , star_tag_mention[i])   # individual_repo_info is the third function which is inside here\n",
    "        all_repos_intopic_dict['USERNAME'].append(repo_data[0])\n",
    "        all_repos_intopic_dict['REPO_NAME'].append(repo_data[1])\n",
    "        all_repos_intopic_dict['STARS'].append(repo_data[2])\n",
    "        all_repos_intopic_dict['REPO_LINK'].append(repo_data[3])\n",
    "\n",
    "    return pd.DataFrame(all_repos_intopic_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e24d1-1c5d-431b-8ef4-0012602953ba",
   "metadata": {},
   "source": [
    "## Third_function : Individual repository complete_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd06a6d-be5d-4d85-91e0-7069f40a3b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts the username,repo_name,repo_links and star_counts from h3_class_mention and star_tag_mention\n",
    "# These 2 (h3 and star) are extracted in second function.\n",
    "# Thus this third function takes two input parameters (h3_class_mention and star__tag_mention)\n",
    "# Name of this function is \"individual_repo_info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbe28396-4464-4049-85f7-5bf284bed7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_repo_info(h3_class_mention, star_tag_mention):# input parameter names of function could be anything.It doesnt matter,but while applying,choose the right variables\n",
    "    a_class_mention = h3_class_mention.find_all('a') \n",
    "    username = a_class_mention[0].text.strip()\n",
    "    repo_name = a_class_mention[1].text.strip()\n",
    "    base_url = 'https://github.com'\n",
    "    repo_link = base_url+a_class_mention[1]['href']\n",
    "    star_counts = parse_star_count(star_tag_mention.text)\n",
    "    return username , repo_name , star_counts , repo_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19426ee-b1e2-4483-b4be-ad8e59fe64b9",
   "metadata": {},
   "source": [
    "## Fourth function : to convert the star counts to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5544ffa4-557b-4cc3-82cc-f4c818ebf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will remove the string'k' if available in the star counts \n",
    "# convert the remaining character into the float type\n",
    "# multiply the float number with 1000\n",
    "# finally convert the star count to integers\n",
    "# name of this function is parse_star_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0548a4a-dbb2-48ba-8c94-6213176f8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(star_str):   # It takes input parameter as string which is extracted from the star_tags.text\n",
    "    star_str = star_str.strip()\n",
    "    if star_str[-1] == 'k':\n",
    "        return int(float(star_str.replace('k',''))*1000)\n",
    "    return star_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f736f-469c-41c6-ada3-46844c9cf154",
   "metadata": {},
   "source": [
    "## Fifth function : extracting topic-name and url from the dataframe created from first function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e30a0-3d8b-4344-b765-e033ac0cfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will extract the TOPIC NAME and URL links from the first dataframe \n",
    "# it will further scrape those url links through functions which are embedded inside this function\n",
    "# I will call this function name as \"meta_second_stage_scraper\"\n",
    "# There will be another function inside it which will do the actual scrapping ,that will be the sixth function and I am gonna call it \"second_stage_scraper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "808427ad-5020-4ff9-9262-00d5308298ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_second_stage_scraper():  # No input parameter is required as it will first take the dataframe and then extract the NAME and URL\n",
    "    print(\"Scraping list of topics from the github/topics...\")\n",
    "    recreate_df = first_stage_scraper()   #first_stage_scraper() creates a df which is stored in variable named \"recreate_df\"\n",
    "    for index,row in recreate_df.iterrows():\n",
    "        print(f\"Scraping top repositories for {row['TOPIC_NAME']}.....\")\n",
    "        second_stage_scraper(row['TOPIC_NAME'] , row['LINKS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f115f6d-c97b-4460-abd4-9b25a4a6e8ed",
   "metadata": {},
   "source": [
    "## Sixth function : It takes individual topic_url and scrape it using embedded functions present within this function and also it creates a csv file of the topic from the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c492a0d-a470-47c7-aebe-089e21ace3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of this function as mentioned in the fifth function notes will be \"second__stage_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64901beb-a060-4307-a5b9-88c2c7aca9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_stage_scraper(topic_name , topic_url):\n",
    "    fname = topic_name + '.csv'\n",
    "    if os.path.exists(fname):\n",
    "        print(f\"The file {fname} already exists.Skipping....\")\n",
    "        return\n",
    "    df = all_repos_of_each_topic(topic_url)        # this is the third function and it returns a dataframe ,that's why variable 'df'\n",
    "    df.to_csv(fname , index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b963924-36f9-475b-8744-6e065a7c45d7",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58e1e4aa-c89c-4684-80bd-7a8ea558c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics from the github/topics...\n",
      "Scraping top repositories for 3D.....\n",
      "Scraping top repositories for Ajax.....\n",
      "Scraping top repositories for Algorithm.....\n",
      "Scraping top repositories for Amp.....\n",
      "Scraping top repositories for Android.....\n",
      "Scraping top repositories for Angular.....\n",
      "Scraping top repositories for Ansible.....\n",
      "Scraping top repositories for API.....\n",
      "Scraping top repositories for Arduino.....\n",
      "Scraping top repositories for ASP.NET.....\n",
      "Scraping top repositories for Awesome Lists.....\n",
      "Scraping top repositories for Amazon Web Services.....\n",
      "Scraping top repositories for Azure.....\n",
      "Scraping top repositories for Babel.....\n",
      "Scraping top repositories for Bash.....\n",
      "Scraping top repositories for Bitcoin.....\n",
      "Scraping top repositories for Bootstrap.....\n",
      "Scraping top repositories for Bot.....\n",
      "Scraping top repositories for C.....\n",
      "Scraping top repositories for Chrome.....\n",
      "Scraping top repositories for Chrome extension.....\n",
      "Scraping top repositories for Command-line interface.....\n",
      "Scraping top repositories for Clojure.....\n",
      "Scraping top repositories for Code quality.....\n",
      "Scraping top repositories for Code review.....\n",
      "Scraping top repositories for Compiler.....\n",
      "Scraping top repositories for Continuous integration.....\n",
      "Scraping top repositories for C++.....\n",
      "Scraping top repositories for Cryptocurrency.....\n",
      "Scraping top repositories for Crystal.....\n"
     ]
    }
   ],
   "source": [
    "meta_second_stage_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28197ec7-dd9e-4d04-87e3-90d5584cdcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics from the github/topics...\n",
      "Scraping top repositories for 3D.....\n",
      "The file 3D.csv already exists.Skipping....\n",
      "Scraping top repositories for Ajax.....\n",
      "The file Ajax.csv already exists.Skipping....\n",
      "Scraping top repositories for Algorithm.....\n",
      "The file Algorithm.csv already exists.Skipping....\n",
      "Scraping top repositories for Amp.....\n",
      "The file Amp.csv already exists.Skipping....\n",
      "Scraping top repositories for Android.....\n",
      "The file Android.csv already exists.Skipping....\n",
      "Scraping top repositories for Angular.....\n",
      "The file Angular.csv already exists.Skipping....\n",
      "Scraping top repositories for Ansible.....\n",
      "The file Ansible.csv already exists.Skipping....\n",
      "Scraping top repositories for API.....\n",
      "The file API.csv already exists.Skipping....\n",
      "Scraping top repositories for Arduino.....\n",
      "The file Arduino.csv already exists.Skipping....\n",
      "Scraping top repositories for ASP.NET.....\n",
      "The file ASP.NET.csv already exists.Skipping....\n",
      "Scraping top repositories for Awesome Lists.....\n",
      "The file Awesome Lists.csv already exists.Skipping....\n",
      "Scraping top repositories for Amazon Web Services.....\n",
      "The file Amazon Web Services.csv already exists.Skipping....\n",
      "Scraping top repositories for Azure.....\n",
      "The file Azure.csv already exists.Skipping....\n",
      "Scraping top repositories for Babel.....\n",
      "The file Babel.csv already exists.Skipping....\n",
      "Scraping top repositories for Bash.....\n",
      "The file Bash.csv already exists.Skipping....\n",
      "Scraping top repositories for Bitcoin.....\n",
      "The file Bitcoin.csv already exists.Skipping....\n",
      "Scraping top repositories for Bootstrap.....\n",
      "The file Bootstrap.csv already exists.Skipping....\n",
      "Scraping top repositories for Bot.....\n",
      "The file Bot.csv already exists.Skipping....\n",
      "Scraping top repositories for C.....\n",
      "The file C.csv already exists.Skipping....\n",
      "Scraping top repositories for Chrome.....\n",
      "The file Chrome.csv already exists.Skipping....\n",
      "Scraping top repositories for Chrome extension.....\n",
      "The file Chrome extension.csv already exists.Skipping....\n",
      "Scraping top repositories for Command-line interface.....\n",
      "The file Command-line interface.csv already exists.Skipping....\n",
      "Scraping top repositories for Clojure.....\n",
      "The file Clojure.csv already exists.Skipping....\n",
      "Scraping top repositories for Code quality.....\n",
      "The file Code quality.csv already exists.Skipping....\n",
      "Scraping top repositories for Code review.....\n",
      "The file Code review.csv already exists.Skipping....\n",
      "Scraping top repositories for Compiler.....\n",
      "The file Compiler.csv already exists.Skipping....\n",
      "Scraping top repositories for Continuous integration.....\n",
      "The file Continuous integration.csv already exists.Skipping....\n",
      "Scraping top repositories for C++.....\n",
      "The file C++.csv already exists.Skipping....\n",
      "Scraping top repositories for Cryptocurrency.....\n",
      "The file Cryptocurrency.csv already exists.Skipping....\n",
      "Scraping top repositories for Crystal.....\n",
      "The file Crystal.csv already exists.Skipping....\n"
     ]
    }
   ],
   "source": [
    "meta_second_stage_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdb017-48c1-4ec8-8b39-62f2af16f9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a0ce25-3861-4bd0-91bb-12688192c56d",
   "metadata": {},
   "source": [
    "## Rough work below to check some code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f7d957a-c16f-4407-a94d-6899ceed29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = first_stage_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69d33254-a9e0-4cad-b86f-05e976990fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3D', 'https://github.com/topics/3d'), ('Ajax', 'https://github.com/topics/ajax'), ('Algorithm', 'https://github.com/topics/algorithm'), ('Amp', 'https://github.com/topics/amphp'), ('Android', 'https://github.com/topics/android'), ('Angular', 'https://github.com/topics/angular'), ('Ansible', 'https://github.com/topics/ansible'), ('API', 'https://github.com/topics/api'), ('Arduino', 'https://github.com/topics/arduino'), ('ASP.NET', 'https://github.com/topics/aspnet'), ('Awesome Lists', 'https://github.com/topics/awesome'), ('Amazon Web Services', 'https://github.com/topics/aws'), ('Azure', 'https://github.com/topics/azure'), ('Babel', 'https://github.com/topics/babel'), ('Bash', 'https://github.com/topics/bash'), ('Bitcoin', 'https://github.com/topics/bitcoin'), ('Bootstrap', 'https://github.com/topics/bootstrap'), ('Bot', 'https://github.com/topics/bot'), ('C', 'https://github.com/topics/c'), ('Chrome', 'https://github.com/topics/chrome'), ('Chrome extension', 'https://github.com/topics/chrome-extension'), ('Command-line interface', 'https://github.com/topics/cli'), ('Clojure', 'https://github.com/topics/clojure'), ('Code quality', 'https://github.com/topics/code-quality'), ('Code review', 'https://github.com/topics/code-review'), ('Compiler', 'https://github.com/topics/compiler'), ('Continuous integration', 'https://github.com/topics/continuous-integration'), ('C++', 'https://github.com/topics/cpp'), ('Cryptocurrency', 'https://github.com/topics/cryptocurrency'), ('Crystal', 'https://github.com/topics/crystal')]\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for index,row in first_df.iterrows():\n",
    "    value1 = row['TOPIC_NAME']\n",
    "    value2 = row['LINKS']\n",
    "    lst.append((value1 , value2))\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a30330-481c-4a66-bb87-64584dd67eed",
   "metadata": {},
   "source": [
    "## Peeping and getting inside each TOPIC - Investigating username,repo_name,repo_links and star_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d372a-94d7-426a-86aa-6896a7a7b1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
